#!/usr/bin/env python3
"""
Script to fetch and cache Groq model limits.
Run this once to populate the limits table, then the limits are stored in code.
"""

import os
import requests
import json
from dotenv import load_dotenv

load_dotenv()

def fetch_all_model_limits():
    """Fetch limits for all available Groq models."""
    api_key = os.getenv('GROQ_API_KEY')
    if not api_key:
        print("Error: GROQ_API_KEY not found in environment")
        return None
    
    headers = {'Authorization': f'Bearer {api_key}'}
    
    # Get all models
    response = requests.get('https://api.groq.com/openai/v1/models', headers=headers)
    if response.status_code != 200:
        print(f"Error fetching models: {response.status_code}")
        return None
    
    models = response.json().get('data', [])
    
    # Filter to only chat completion models (exclude TTS, etc.)
    chat_models = [m for m in models if not any(x in m.get('id', '').lower() for x in ['tts', 'whisper', 'guard', 'safeguard'])]
    
    limits = {}
    
    for model in chat_models:
        model_id = model.get('id')
        print(f"Fetching limits for {model_id}...")
        
        # Get model details
        model_response = requests.get(
            f'https://api.groq.com/openai/v1/models/{model_id}',
            headers=headers
        )
        
        if model_response.status_code == 200:
            model_data = model_response.json()
            context_window = model_data.get('context_window')
            max_completion = model_data.get('max_completion_tokens')
            max_input = context_window - max_completion if (context_window and max_completion) else None
            
            limits[model_id] = {
                'context_window': context_window,
                'max_completion_tokens': max_completion,
                'max_input_tokens': max_input
            }
            print(f"  Context: {context_window}, Max Input: {max_input}, Max Completion: {max_completion}")
        else:
            print(f"  Failed: {model_response.status_code}")
    
    return limits

def generate_limits_code(limits):
    """Generate Python code with the limits as a dictionary."""
    code = """# Groq Model Limits
# Auto-generated by fetch_groq_limits.py
# DO NOT EDIT MANUALLY - Run fetch_groq_limits.py to update

GROQ_MODEL_LIMITS = {
"""
    
    for model_id, limit_data in sorted(limits.items()):
        context = limit_data.get('context_window', 'None')
        max_input = limit_data.get('max_input_tokens', 'None')
        max_completion = limit_data.get('max_completion_tokens', 'None')
        
        code += f'    "{model_id}": {{\n'
        code += f'        "context_window": {context},\n'
        code += f'        "max_input_tokens": {max_input},\n'
        code += f'        "max_completion_tokens": {max_completion},\n'
        code += f'    }},\n'
    
    code += "}\n"
    return code

if __name__ == "__main__":
    print("Fetching Groq model limits...")
    limits = fetch_all_model_limits()
    
    if limits:
        code = generate_limits_code(limits)
        
        # Write to a file
        output_file = 'groq_model_limits.py'
        with open(output_file, 'w') as f:
            f.write(code)
        
        print(f"\n✓ Limits saved to {output_file}")
        print(f"✓ Found limits for {len(limits)} models")
    else:
        print("Failed to fetch limits")














